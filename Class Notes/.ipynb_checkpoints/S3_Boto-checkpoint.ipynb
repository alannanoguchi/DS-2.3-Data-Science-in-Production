{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "- How we can dump large dataset on S3 and read it by using Boto\n",
    "\n",
    "- Learn this by uploading churn dataset on S3, train a Keras DL model by `Churn_Modelling.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S3 + Boto:\n",
    "- pip install awscli (!pip install awscli on Google Colab)\n",
    "- $ aws configure (!aws configure on Google Colab)\n",
    "- AWS Access Key ID [None]: ...\n",
    "- AWS Secret Access Key [None]: ...\n",
    "- Default region name [None]: ...\n",
    "- Default output format [None]: ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
      "0          1    15634602  Hargrave          619    France  Female   42   \n",
      "1          2    15647311      Hill          608     Spain  Female   41   \n",
      "2          3    15619304      Onio          502    France  Female   42   \n",
      "3          4    15701354      Boni          699    France  Female   39   \n",
      "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
      "\n",
      "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
      "0       2       0.00              1          1               1   \n",
      "1       1   83807.86              1          0               1   \n",
      "2       8  159660.80              3          1               0   \n",
      "3       1       0.00              2          0               0   \n",
      "4       2  125510.82              1          1               1   \n",
      "\n",
      "   EstimatedSalary  Exited  \n",
      "0        101348.88       1  \n",
      "1        112542.58       0  \n",
      "2        113931.57       1  \n",
      "3         93826.63       0  \n",
      "4         79084.10       0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "\n",
    "bucket = \"makeschoolds\"\n",
    "file_name = \"data/Churn_Modelling.csv\"\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "# 's3' is a key word. create connection to S3 using default config and all buckets within S3\n",
    "\n",
    "obj = s3.get_object(Bucket=bucket, Key=file_name)\n",
    "# get object and file (key) from bucket\n",
    "\n",
    "df = pd.read_csv(obj['Body']) # 'Body' is a key word\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Churn Prediction\n",
    "\n",
    "- Lets first read: https://medium.com/@pushkarmandot/build-your-first-deep-learning-neural-network-model-using-keras-in-python-a90b5864116d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "X = df.iloc[:, 3:13].values\n",
    "y = df.iloc[:, 13].values\n",
    "\n",
    "print(X)\n",
    "print(X.shape)\n",
    "print(y)\n",
    "\n",
    "label_encoder_X_1 = LabelEncoder()\n",
    "X[:, 1] = label_encoder_X_1.fit_transform(X[:, 1])\n",
    "label_encoder_X_2 = LabelEncoder()\n",
    "X[:, 2] = label_encoder_X_2.fit_transform(X[:, 2])\n",
    "print(X)\n",
    "print(X.shape)\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(categorical_features=[1])\n",
    "X = one_hot_encoder.fit_transform(X).toarray()\n",
    "X = X[:, 1:]\n",
    "# print('M:')\n",
    "# print(X[:, :10])\n",
    "# print(X[:, 10])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "print(X_train.shape)\n",
    "\n",
    "classifier = Sequential()\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(output_dim=6, init='uniform', activation='relu', input_dim=11))\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(output_dim=6, init='uniform', activation='relu'))\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(output_dim=1, init='uniform', activation='sigmoid'))\n",
    "# Compiling Neural Network\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# Fitting our model\n",
    "classifier.fit(X_train, y_train, batch_size=10, nb_epoch=50, verbose=1)\n",
    "# Predicting the Test set results\n",
    "y_predict = classifier.predict(X_test)\n",
    "print(y_predict)\n",
    "y_predict = (y_predict > 0.5)\n",
    "cm = confusion_matrix(y_test, y_predict)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "table Population already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3445c2691f14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mcon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CREATE TABLE Population(id INTEGER PRIMARY KEY, country TEXT, population INT)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"INSERT INTO Population VALUES(NULL,'Germany',81197537)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"INSERT INTO Population VALUES(NULL,'France', 66415161)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: table Population already exists"
     ]
    }
   ],
   "source": [
    "import sqlite3 as lite\n",
    "\n",
    "con = lite.connect('population.db')\n",
    "\n",
    "with con:\n",
    "    cur = con.cursor()\n",
    "    cur.execute(\"CREATE TABLE Population(id INTEGER PRIMARY KEY, country TEXT, population INT)\")\n",
    "    cur.execute(\"INSERT INTO Population VALUES(NULL,'Germany',81197537)\")\n",
    "    cur.execute(\"INSERT INTO Population VALUES(NULL,'France', 66415161)\")\n",
    "    cur.execute(\"INSERT INTO Population VALUES(NULL,'Spain', 46439864)\")\n",
    "    cur.execute(\"INSERT INTO Population VALUES(NULL,'Italy', 60795612)\")\n",
    "    cur.execute(\"INSERT INTO Population VALUES(NULL,'Spain', 46439864)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a SQL syntax in Python that return all records where population field is greater or equal than 50Mâ€©",
    "from Population table in population database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Germany\n",
      "France\n",
      "Italy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('population.db')\n",
    "query = \"SELECT country FROM Population WHERE population > 50000000;\"\n",
    "\n",
    "df = pd.read_sql_query(query, conn)\n",
    "\n",
    "for country in df['country']:\n",
    "    print(country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spain\n",
      "Spain\n"
     ]
    }
   ],
   "source": [
    "query_1 = \"SELECT country FROM Population WHERE country LIKE 'S%'\"     # query countrys that begin with S\n",
    "\n",
    "df = pd.read_sql_query(query_1, conn)\n",
    "\n",
    "for country in df['country']:\n",
    "    print(country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the MongoDB and insert and have query in Python\n",
    "\n",
    "Read: https://marcobonzanini.com/2015/09/07/getting-started-wimport pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('population.db')\n",
    "query = \"SELECT country FROM Population WHERE population > 50000000;\"\n",
    "\n",
    "df = pd.read_sql_query(query, conn)\n",
    "\n",
    "for country in df['country']:\n",
    "    print(country)ith-mongodb-and-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n",
    "\n",
    "client = MongoClient()\n",
    "\n",
    "db = client['tutorial']\n",
    "coll = db['articles']\n",
    "\n",
    "doc = {\n",
    "    \"title\": \"An article about MongoDB and Python\",\n",
    "    \"author\": \"Marco\",\n",
    "    \"publication_date\": datetime.utcnow(),\n",
    "    # more fields\n",
    "}\n",
    "\n",
    "doc_id = coll.insert_one(doc).inserted_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "\n",
    "client = MongoClient()\n",
    "\n",
    "db = client['tutorial']\n",
    "coll = db['articles']\n",
    "\n",
    "for doc in coll.find():\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syntaxes:\n",
    "\n",
    "sudo mkdir -p /data/db\n",
    "\n",
    "whoami\n",
    "\n",
    "sudo chown miladtoutounchian /data/db\n",
    "\n",
    "./bin/mongod\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We want to call GitHub API in Python. \n",
    "\n",
    "To do this use the following hints:\n",
    "\n",
    "1- import requests\n",
    "\n",
    "2- url = 'https://api.github.com/search/repositories?q=tensorflow'\n",
    "\n",
    "Lets print the top 10 repositories for Tensorflow from GitHub APIâ€©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91022\n"
     ]
    }
   ],
   "source": [
    "url = 'https://api.github.com/search/repositories?q=tensorflow'\n",
    "print(requests.get(url).json()['total_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
